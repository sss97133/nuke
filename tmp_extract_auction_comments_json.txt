"/**\n * EXTRACT AUCTION COMMENTS\n * Pulls all comments from a BaT auction and analyzes them\n */\n\nimport { serve } from \"https://deno.land/std@0.168.0/http/server.ts\"\nimport { createClient } from 'https://esm.sh/@supabase/supabase-js@2'\nimport { DOMParser } from 'https://deno.land/x/deno_dom@v0.1.38/deno-dom-wasm.ts'\n\nconst corsHeaders = {\n  'Access-Control-Allow-Origin': '*',\n  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',\n}\n\nasync function sha256Hex(text: string): Promise<string> {\n  const data = new TextEncoder().encode(text);\n  const digest = await crypto.subtle.digest('SHA-256', data);\n  const bytes = Array.from(new Uint8Array(digest));\n  return bytes.map((b) => b.toString(16).padStart(2, '0')).join('');\n}\n\nfunction normalizeUrl(raw: string): string {\n  try {\n    const u = new URL(raw);\n    u.hash = '';\n    u.search = '';\n    if (!u.pathname.endsWith('/')) u.pathname = `${u.pathname}/`;\n    return u.toString();\n  } catch {\n    return String(raw).split('#')[0].split('?')[0];\n  }\n}\n\nasync function trySaveHtmlSnapshot(args: {\n  supabase: any\n  platform: string\n  listingUrl: string\n  fetchMethod: string\n  httpStatus: number | null\n  success: boolean\n  errorMessage: string | null\n  html: string | null\n  metadata?: Record<string, unknown>\n}): Promise<void> {\n  const {\n    supabase,\n    platform,\n    listingUrl,\n    fetchMethod,\n    httpStatus,\n    success,\n    errorMessage,\n    html,\n    metadata,\n  } = args\n\n  try {\n    const htmlText = html ?? null\n    const htmlSha = htmlText ? await sha256Hex(htmlText) : null\n    const contentLength = htmlText ? htmlText.length : 0\n\n    const payload: any = {\n      platform,\n      listing_url: listingUrl,\n      fetch_method: fetchMethod,\n      http_status: httpStatus,\n      success,\n      error_message: errorMessage,\n      html: htmlText,\n      html_sha256: htmlSha,\n      content_length: contentLength,\n      metadata: metadata || {},\n    }\n\n    // Dedup is enforced by a PARTIAL unique index in SQL:\n    //   UNIQUE(platform, listing_url, html_sha256) WHERE html_sha256 IS NOT NULL\n    // Supabase/PostgREST upsert cannot express the partial-index predicate, so we use plain INSERT\n    // and treat unique-violation as a no-op.\n    const { error } = await supabase\n      .from('listing_page_snapshots')\n      .insert(payload)\n\n    if (error) {\n      // 23505 = unique_violation (duplicate snapshot); ignore.\n      if (String(error.code || '') === '23505') return\n      console.warn('listing_page_snapshots insert failed (non-fatal):', error?.message || String(error))\n    }\n  } catch (e: any) {\n    console.warn('listing_page_snapshots save failed (non-fatal):', e?.message || String(e))\n  }\n}\n\nserve(async (req) => {\n  if (req.method === 'OPTIONS') return new Response('ok', { headers: corsHeaders })\n\n  try {\n    const supabaseUrl = (Deno.env.get('SUPABASE_URL') ?? '').trim()\n    const serviceRoleKey = (Deno.env.get('SUPABASE_SERVICE_ROLE_KEY') ?? Deno.env.get('SERVICE_ROLE_KEY') ?? '').trim()\n\n    if (!supabaseUrl) throw new Error('Missing SUPABASE_URL')\n    if (!serviceRoleKey) throw new Error('Missing SUPABASE_SERVICE_ROLE_KEY')\n\n    const supabase = createClient(supabaseUrl, serviceRoleKey)\n\n    const { auction_url, auction_event_id, vehicle_id } = await req.json()\n    if (!auction_url) throw new Error('Missing auction_url')\n\n    const auctionUrlRaw = String(auction_url)\n    const auctionUrlNorm = normalizeUrl(auctionUrlRaw)\n    const auctionUrlAlt = auctionUrlNorm.endsWith('/') ? auctionUrlNorm.slice(0, -1) : `${auctionUrlNorm}/`\n    const urlCandidates = Array.from(new Set([auctionUrlRaw, auctionUrlNorm, auctionUrlAlt].filter(Boolean)))\n\n    console.log(`Extracting comments from: ${auctionUrlNorm}`)\n\n    // Resolve auction_event_id if caller didn't provide it (best-effort convenience).\n    const platformGuess = auctionUrlNorm.includes('bringatrailer.com') ? 'bat' : null\n    let eventId: string | null = auction_event_id ? String(auction_event_id) : null\n    if (!eventId && platformGuess) {\n      const { data: ev } = await supabase\n        .from('auction_events')\n        .select('id')\n        .eq('source', platformGuess)\n        .in('source_url', urlCandidates)\n        .limit(1)\n        .maybeSingle()\n      if (ev?.id) eventId = String(ev.id)\n    }\n    if (!eventId) {\n      console.warn('Missing auction_event_id (and could not resolve by listing_url) - proceeding without auction_event_id')\n    }\n\n    // Resolve vehicle_id for UI filters + auction pulse; prefer explicit input, else read from auction_events.\n    let vehicleId: string | null = vehicle_id ? String(vehicle_id) : null\n    if (!vehicleId && eventId) {\n      const { data: ev2 } = await supabase\n        .from('auction_events')\n        .select('vehicle_id')\n        .eq('id', eventId)\n        .maybeSingle()\n      if (ev2?.vehicle_id) vehicleId = String(ev2.vehicle_id)\n    }\n    if (!vehicleId && platformGuess === 'bat') {\n      const { data: ext } = await supabase\n        .from('external_listings')\n        .select('vehicle_id')\n        .eq('platform', 'bat')\n        .in('listing_url', urlCandidates)\n        .limit(1)\n        .maybeSingle()\n      if (ext?.vehicle_id) vehicleId = String(ext.vehicle_id)\n    }\n    if (!vehicleId && platformGuess === 'bat') {\n      const { data: v1 } = await supabase\n        .from('vehicles')\n        .select('id')\n        .in('bat_auction_url', urlCandidates)\n        .limit(1)\n        .maybeSingle()\n      if (v1?.id) vehicleId = String(v1.id)\n    }\n    if (!vehicleId && platformGuess === 'bat') {\n      const { data: v2 } = await supabase\n        .from('vehicles')\n        .select('id')\n        .in('discovery_url', urlCandidates)\n        .limit(1)\n        .maybeSingle()\n      if (v2?.id) vehicleId = String(v2.id)\n    }\n    if (!vehicleId) throw new Error('Missing vehicle_id (and could not resolve by auction_event_id, external_listings, or vehicles URLs)')\n\n    // ⚠️ FREE MODE: Direct HTML fetch (no Firecrawl due to budget constraints)\n    // BaT comments may be in HTML or require JS rendering - try direct fetch first\n    console.log('Fetching BaT page HTML directly (free mode - no Firecrawl)...')\n    \n    // User agent rotation for IP safety (avoids detection patterns)\n    const userAgents = [\n      'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n      'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',\n      'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',\n      'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',\n    ]\n    const randomUserAgent = userAgents[Math.floor(Math.random() * userAgents.length)]\n    \n    // Random delay to appear more human (1-3 seconds)\n    const humanDelay = Math.random() * 2000 + 1000\n    await new Promise(resolve => setTimeout(resolve, humanDelay))\n    \n    let html = ''\n    try {\n      const response = await fetch(auctionUrlNorm, {\n        headers: {\n          'User-Agent': randomUserAgent,\n          'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n          'Accept-Language': 'en-US,en;q=0.5',\n          'Accept-Encoding': 'gzip, deflate, br',\n          'Connection': 'keep-alive',\n          'Upgrade-Insecure-Requests': '1',\n          'Referer': 'https://www.google.com/', // Appear to come from search\n        },\n        signal: AbortSignal.timeout(30000)\n      })\n      \n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`)\n      }\n      \n      html = await response.text()\n      \n      if (!html || html.length < 1000) {\n        throw new Error(`Direct fetch returned insufficient HTML (${html?.length || 0} chars)`)\n      }\n      \n      console.log(`Direct fetch returned ${html.length} characters of HTML`)\n\n      // Evidence-first: store HTML snapshot so we can re-parse later without re-scraping.\n      // This is especially useful in free mode to reduce repeated site hits.\n      if (platformGuess === 'bat') {\n        await trySaveHtmlSnapshot({\n          supabase,\n          platform: 'bat',\n          listingUrl: auctionUrlNorm,\n          fetchMethod: 'direct',\n          httpStatus: response.status,\n          success: true,\n          errorMessage: null,\n          html,\n          metadata: {\n            extractor: 'extract-auction-comments',\n            mode: 'free',\n            user_agent: randomUserAgent,\n            vehicle_id: vehicleId,\n            auction_event_id: eventId,\n          },\n        })\n      }\n    } catch (e: any) {\n      console.error(`Direct fetch failed: ${e.message}`)\n\n      if (platformGuess === 'bat') {\n        await trySaveHtmlSnapshot({\n          supabase,\n          platform: 'bat',\n          listingUrl: auctionUrlNorm,\n          fetchMethod: 'direct',\n          httpStatus: null,\n          success: false,\n          errorMessage: e?.message ? String(e.message) : 'Direct fetch failed',\n          html: null,\n          metadata: {\n            extractor: 'extract-auction-comments',\n            mode: 'free',\n            user_agent: randomUserAgent,\n            vehicle_id: vehicleId,\n            auction_event_id: eventId,\n          },\n        })\n      }\n\n      throw new Error(`Direct HTML fetch failed: ${e.message}. BaT comments may require JavaScript rendering (Firecrawl needed).`)\n    }\n    \n    // ⚠️ PRIORITY: Extract from embedded JSON comments array (BaT embeds comments as \"comments\":[{...}])\n    // This is the FREE way to get comments without JavaScript rendering!\n    let commentsFromJson: any[] = []\n    try {\n      // Pattern 1: Look for \"comments\":[{...},...,{...}] in HTML\n      const commentsMatch = html.match(/\"comments\":\\s*\\[([\\s\\S]*?)\\](?=,\"[a-z])/)\n      if (commentsMatch && commentsMatch[1]) {\n        try {\n          const arrayContent = '[' + commentsMatch[1] + ']'\n          const parsed = JSON.parse(arrayContent)\n          if (Array.isArray(parsed) && parsed.length > 0) {\n            console.log(`Found ${parsed.length} comments in embedded JSON array`)\n            commentsFromJson = parsed\n          }\n        } catch (parseErr: any) {\n          console.warn(`Failed to parse comments JSON array: ${parseErr?.message}`)\n        }\n      }\n      \n      // Pattern 2: Try __NEXT_DATA__ (BaT might use Next.js for some pages)\n      if (commentsFromJson.length === 0) {\n        const nextDataPattern = /<script[^>]*id=[\"']__NEXT_DATA__[\"'][^>]*>([\\s\\S]*?)<\\/script>/i\n        const nextDataMatch = html.match(nextDataPattern)\n        if (nextDataMatch && nextDataMatch[1]) {\n          try {\n            const nextData = JSON.parse(nextDataMatch[1])\n            const pageData = nextData?.props?.pageProps?.pageData || nextData?.props?.pageProps || {}\n            const listing = pageData.listing || pageData\n            const rawComments = pageData.comments || listing?.comments || []\n            \n            if (Array.isArray(rawComments) && rawComments.length > 0) {\n              console.log(`Found ${rawComments.length} comments in __NEXT_DATA__`)\n              commentsFromJson = rawComments\n            }\n          } catch (e: any) {\n            console.warn(`Failed to parse __NEXT_DATA__ for comments: ${e?.message}`)\n          }\n        }\n      }\n      \n      // Pattern 3: Try individual comment objects (fallback for edge cases)\n      if (commentsFromJson.length === 0) {\n        const objectMatches = html.matchAll(/\\{\"channels\":\\[.*?\"type\":\"(bat-bid|comment)\".*?\\}/g)\n        const found: any[] = []\n        for (const match of objectMatches) {\n          try {\n            const obj = JSON.parse(match[0])\n            if (obj?.type && (obj.type === 'bat-bid' || obj.type === 'comment')) {\n              found.push(obj)\n            }\n          } catch { /* skip malformed */ }\n        }\n        if (found.length > 0) {\n          console.log(`Found ${found.length} comments from individual JSON objects`)\n          commentsFromJson = found\n        }\n      }\n    } catch (e: any) {\n      console.warn(`Failed to extract comments from JSON: ${e?.message}`)\n    }\n\n    const doc = new DOMParser().parseFromString(html, 'text/html')\n    if (!doc) throw new Error('Failed to parse HTML (DOMParser returned null)')\n\n    // Extract auction metadata\n    const auctionEndMatch = html.match(/Auction ended?[:\\s]+([A-Za-z]+\\s+\\d{1,2},\\s+\\d{4})/i)\n    const auctionEndDate = auctionEndMatch ? new Date(auctionEndMatch[1]) : new Date()\n\n    const comments = []\n    const authorSet = new Set<string>()\n    const authorProfileUrls = new Map<string, string>() // Map author username to profile URL\n    \n    // Process comments from embedded JSON (preferred method - FREE, no JS needed!)\n    if (commentsFromJson.length > 0) {\n      console.log(`Processing ${commentsFromJson.length} comments from embedded JSON...`)\n      for (let i = 0; i < commentsFromJson.length; i++) {\n        const c = commentsFromJson[i]\n        const authorRaw = String(c?.authorName || c?.author || '').trim()\n        const author = authorRaw.replace(/\\s*\\(The\\s+Seller\\)/i, '').trim() || 'Unknown'\n        const isSeller = authorRaw.toLowerCase().includes('(the seller)')\n        \n        // Parse timestamp (BaT uses Unix timestamp in seconds)\n        const timestamp = c?.timestamp ? (typeof c.timestamp === 'number' ? new Date(c.timestamp * 1000) : new Date(c.timestamp)) : null\n        const posted_at = timestamp || auctionEndDate\n        \n        // Extract text (may be HTML, strip tags)\n        const rawText = String(c?.content || c?.comment || c?.text || '').replace(/<[^>]+>/g, ' ').replace(/\\s+/g, ' ').trim()\n        if (!rawText || rawText.length < 3) continue\n        \n        // Detect comment type\n        const isBid = c?.type === 'bat-bid' || /bid\\s+placed\\s+by/i.test(rawText)\n        const bidAmount = (isBid && c?.bidAmount) ? (typeof c.bidAmount === 'number' ? c.bidAmount : parseFloat(String(c.bidAmount).replace(/,/g, ''))) : null\n        \n        const comment_type = \n          bidAmount ? 'bid' :\n          isSeller ? 'seller_response' :\n          rawText.includes('?') ? 'question' :\n          'observation'\n        \n        const hours_until_close = timestamp ? (auctionEndDate.getTime() - posted_at.getTime()) / (1000 * 60 * 60) : 0\n        \n        // Generate content hash for idempotency\n        const content_hash = await sha256Hex([\n          'bat',\n          String(auctionUrlNorm),\n          String(i + 1),\n          String(posted_at.toISOString()),\n          String(author),\n          String(rawText),\n        ].join('|'))\n        \n        // Extract profile URL if available\n        if (c?.authorProfileUrl || (author && author !== 'Unknown')) {\n          const profileUrl = c?.authorProfileUrl || `https://bringatrailer.com/member/${author.toLowerCase().replace(/\\s+/g, '-')}`\n          authorProfileUrls.set(author, profileUrl)\n        }\n        \n        comments.push({\n          auction_event_id: eventId,\n          vehicle_id: vehicleId,\n          // Canonical platform key used across the DB is 'bat' (matches external_listings.platform, auction_events.source).\n          platform: platformGuess,\n          source_url: String(auctionUrlNorm),\n          content_hash,\n          sequence_number: i + 1,\n          posted_at: posted_at.toISOString(),\n          hours_until_close: Math.max(0, hours_until_close),\n          author_username: author,\n          is_seller: isSeller,\n          author_total_likes: typeof c?.likes === 'number' ? c.likes : 0,\n          comment_type,\n          comment_text: rawText,\n          word_count: rawText.split(/\\s+/).length,\n          has_question: rawText.includes('?'),\n          has_media: Boolean(c?.hasImage || c?.hasVideo),\n          bid_amount: bidAmount,\n          comment_likes: typeof c?.commentLikes === 'number' ? c.commentLikes : 0\n        })\n        \n        if (author && author !== 'Unknown') {\n          authorSet.add(author)\n        }\n      }\n      \n      console.log(`Successfully processed ${comments.length} comments from embedded JSON (free mode)`)\n    }\n    \n    // Fallback: Try DOM parsing if JSON extraction had no comments\n    if (comments.length === 0) {\n      console.log(`No comments found in embedded JSON, trying DOM fallback (may not work without JS rendering)...`)\n      // Extract all comments - try multiple selectors for robustness\n      let commentElements = doc.querySelectorAll('.comment')\n      if (commentElements.length === 0) {\n        // Fallback: look for comment-like structures in comments-javascript-enabled\n        const commentsContainer = doc.querySelector('#comments-javascript-enabled')\n        if (commentsContainer) {\n          // Try to find individual comment blocks by looking for patterns\n          commentElements = commentsContainer.querySelectorAll('[data-cursor-element-id]')\n        }\n      }\n    \n    for (let i = 0; i < commentElements.length; i++) {\n      const el = commentElements[i]\n      \n      // Extract fields - try multiple patterns\n      let dateText = el.querySelector('.comment-datetime')?.textContent?.trim() || ''\n      \n      // Try to find author link first (most reliable)\n      const authorLink = el.querySelector('a[href*=\"/member/\"]') as HTMLAnchorElement | null\n      let authorRaw = authorLink?.textContent?.trim() || ''\n      \n      // If no author link, try other selectors\n      if (!authorRaw) {\n        const authorEl = el.querySelector('[data-bind*=\"authorName\"]') || el.querySelector('.comment-user-name')\n        authorRaw = authorEl?.textContent?.trim() || ''\n      }\n      \n      // If still no author, try to extract from text content patterns\n      const fullText = el.textContent || ''\n      if (!authorRaw && fullText) {\n        // Try patterns like \"12/27/24 at 6:01 PM Username\" or \"Username This author's likes:\"\n        const authorMatch = fullText.match(/(\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}\\s+at\\s+\\d{1,2}:\\d{2}\\s+[AP]M)\\s+([A-Za-z0-9_]+)/i)\n        if (authorMatch) {\n          dateText = authorMatch[1]\n          authorRaw = authorMatch[2]\n        } else {\n          // Fallback: look for username before \"This author's likes:\"\n          const authorMatch2 = fullText.match(/([A-Za-z0-9_]+)\\s+This author's likes:/i)\n          if (authorMatch2) authorRaw = authorMatch2[1]\n        }\n      }\n      \n      // Clean up author name (remove \"The Seller\" suffix, etc) - but keep original for profile URL lookup\n      const authorClean = authorRaw.replace(/\\s*\\(The\\s+Seller\\)/i, '').trim()\n      \n      // Normalize to a stable BaT handle key for attribution + future claiming.\n      const author = String(authorClean).trim() || 'Unknown'\n      \n      // Extract profile URL from author link if available\n      if (authorLink && author && author !== 'Unknown' && author.length > 0) {\n        const href = authorLink.getAttribute('href') || ''\n        if (href) {\n          const profileUrl = href.startsWith('http') ? href : `https://bringatrailer.com${href}`\n          authorProfileUrls.set(author, profileUrl)\n          // Also map original if different and not empty\n          const originalTrimmed = authorRaw.trim()\n          if (originalTrimmed && originalTrimmed !== author) {\n            authorProfileUrls.set(originalTrimmed, profileUrl)\n          }\n        }\n      }\n      \n      // Extract text - try p tag first, then direct textContent\n      let text = el.querySelector('p')?.textContent?.trim() || ''\n      if (!text) {\n        // Try to extract just the comment text, excluding metadata\n        const textMatch = fullText.match(/This comment's likes:[\\s\\S]*?(.+?)(?:Flag as|$)/i)\n        if (textMatch) {\n          text = textMatch[1].trim()\n        } else {\n          // Last resort: use all text but remove common patterns\n          text = fullText\n            .replace(/\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}\\s+at\\s+\\d{1,2}:\\d{2}\\s+[AP]M/gi, '')\n            .replace(/This author's likes:\\s*\\d+/gi, '')\n            .replace(/This comment's likes:\\s*\\d+/gi, '')\n            .replace(/Flag as not constructive/gi, '')\n            .replace(/Keep me in this conversation via email/gi, '')\n            .trim()\n        }\n      }\n      \n      if (!text || text.length < 3) continue // Skip empty or too short\n      \n      // Parse date (format: \"Nov 21 at 3:38 PM\")\n      const posted_at = parseBaTDate(dateText, auctionEndDate)\n      const hours_until_close = (auctionEndDate.getTime() - posted_at.getTime()) / (1000 * 60 * 60)\n      \n      // Detect comment type\n      const isSeller = el.classList.contains('bat_seller_comment')\n      const isBid = text.includes('bid placed by')\n      const isSold = text.includes('Sold on') || text.includes('sold for')\n      \n      const comment_type = \n        isSold ? 'sold' :\n        isBid ? 'bid' :\n        isSeller ? 'seller_response' :\n        text.includes('?') ? 'question' :\n        'observation'\n      \n      // Extract bid amount\n      const bidMatch = text.match(/\\$([0-9,]+)\\s+bid placed by/)\n      const bid_amount = bidMatch ? parseFloat(bidMatch[1].replace(/,/g, '')) : null\n      \n      // Extract likes\n      const authorLikesEl = el.querySelector('.total-likes')\n      const authorLikes = extractNumber(authorLikesEl?.textContent)\n      \n      const commentLikesEl = el.querySelector('.comment-actions-approve')\n      const commentLikes = extractNumber(commentLikesEl?.textContent)\n      \n      // Media detection\n      const has_video = text.toLowerCase().includes('cold start') || text.toLowerCase().includes('video')\n      const has_image = el.querySelector('img') !== null\n\n      // Stable idempotency key (unique on (vehicle_id, content_hash) exists in DB).\n      const content_hash = await sha256Hex(\n        [\n          'bat',\n          String(auctionUrlNorm),\n          String(i + 1),\n          String(posted_at.toISOString()),\n          String(author),\n          String(text),\n        ].join('|')\n      )\n      \n      comments.push({\n        auction_event_id: eventId,\n        vehicle_id: vehicleId,\n        platform: platformGuess,\n        source_url: String(auctionUrlNorm),\n        content_hash,\n        sequence_number: i + 1,\n        posted_at: posted_at.toISOString(),\n        hours_until_close: Math.max(0, hours_until_close),\n        author_username: author,\n        is_seller: isSeller,\n        author_total_likes: authorLikes,\n        comment_type,\n        comment_text: text,\n        word_count: text.split(/\\s+/).length,\n        has_question: text.includes('?'),\n        has_media: has_video || has_image,\n        bid_amount,\n        comment_likes: commentLikes\n      })\n\n      if (author && author !== 'Unknown') {\n        authorSet.add(author)\n      }\n    }\n    } // End of DOM fallback section\n    \n    console.log(`Extracted ${comments.length} comments`)\n\n    // Upsert external identities (platform + handle) with profile URLs so later humans can claim/merge them.\n    // NOTE: This function runs with service role key, so it can write to external_identities.\n    const handleToExternalIdentityId = new Map<string, string>()\n    if (authorSet.size > 0) {\n      const nowIso = new Date().toISOString()\n      const rows = Array.from(authorSet).map((h) => {\n        // Clean handle for URL lookup (remove \"The Seller\" suffix)\n        const cleanHandle = h.replace(/\\s*\\(The\\s+Seller\\)/i, '').trim()\n        // Try to find profile URL for this handle\n        const profileUrl = authorProfileUrls.get(h) || \n                          authorProfileUrls.get(cleanHandle) ||\n                          `https://bringatrailer.com/member/${encodeURIComponent(cleanHandle)}`\n        \n        return {\n          platform: 'bat',\n          // Use the handle as seen on BaT. (We keep it as-is for display; uniqueness is platform+handle.)\n          handle: h,\n          profile_url: profileUrl,\n          last_seen_at: nowIso,\n          updated_at: nowIso,\n        }\n      })\n\n      // Idempotent upsert\n      const { data: upserted, error: upsertErr } = await supabase\n        .from('external_identities')\n        .upsert(rows, { onConflict: 'platform,handle' })\n        .select('id, handle')\n\n      if (upsertErr) {\n        console.warn('Failed to upsert external identities (non-fatal):', upsertErr)\n      } else {\n        ;(upserted || []).forEach((r: any) => {\n          if (r?.handle && r?.id) handleToExternalIdentityId.set(String(r.handle), String(r.id))\n        })\n      }\n    }\n\n    // Attach external identity IDs to comments when possible.\n    const commentsWithIdentities = comments.map((c: any) => ({\n      ...c,\n      external_identity_id: handleToExternalIdentityId.get(String(c.author_username)) || null,\n    }))\n\n    // Store comments (canonical)\n    // Do this BEFORE any legacy BaT table writes so we never end up with partial state\n    // (e.g. bat_bids written but auction_comments missing).\n    if (comments.length > 0) {\n      console.log(`Attempting to upsert ${comments.length} comments...`)\n      const { data: inserted, error } = await supabase\n        .from('auction_comments')\n        .upsert(commentsWithIdentities, { onConflict: 'vehicle_id,content_hash' })\n        .select('id')\n      \n      if (error) {\n        const e: any = error\n        console.error('Upsert error:', e)\n        throw new Error(\n          [\n            'auction_comments upsert failed',\n            e?.message ? `message=${String(e.message)}` : null,\n            e?.code ? `code=${String(e.code)}` : null,\n            e?.details ? `details=${String(e.details)}` : null,\n            e?.hint ? `hint=${String(e.hint)}` : null,\n          ]\n            .filter(Boolean)\n            .join(' | ')\n        )\n      }\n      console.log(`Successfully saved ${inserted?.length || comments.length} comments`)\n    } else {\n      console.warn('No comments to save (comments array is empty)')\n    }\n\n    let batListingId: string | null = null\n    try {\n      const nowIso = new Date().toISOString()\n      const { data: extListing } = await supabase\n        .from('external_listings')\n        .select('id, final_price, current_bid, listing_status, end_date, sold_at, listing_id, metadata')\n        .eq('vehicle_id', vehicleId)\n        .eq('platform', 'bat')\n        .order('updated_at', { ascending: false })\n        .limit(1)\n        .maybeSingle()\n\n      const inferredHighBid = commentsWithIdentities\n        .map((c: any) => (typeof c?.bid_amount === 'number' && Number.isFinite(c.bid_amount) ? c.bid_amount : null))\n        .filter((n: any) => typeof n === 'number')\n        .reduce((acc: number, n: number) => (n > acc ? n : acc), 0)\n\n      // Safety net: If the core extractor didn't set final_price, infer it from the SOLD system comment.\n      const soldCommentText =\n        commentsWithIdentities.find((c: any) => String(c?.comment_type || '').toLowerCase() === 'sold')?.comment_text ||\n        commentsWithIdentities.find((c: any) => /\\bsold\\s+on\\b|\\bsold\\s+for\\b/i.test(String(c?.comment_text || '')))?.comment_text ||\n        null\n\n      const parseMoney = (raw: string | null): number | null => {\n        const m = String(raw || '').match(/\\$([0-9,]+)/)\n        if (!m?.[1]) return null\n        const n = Number(String(m[1]).replace(/,/g, ''))\n        return Number.isFinite(n) && n > 0 ? Math.floor(n) : null\n      }\n\n      const inferredSoldPriceFromComment =\n        soldCommentText\n          ? (\n              parseMoney(String(soldCommentText).match(/\\bfor\\s+(?:USD\\s*)?\\$[0-9,]+/i)?.[0] || soldCommentText) ||\n              parseMoney(soldCommentText)\n            )\n          : null\n\n      const inferredBuyerFromComment = (() => {\n        if (!soldCommentText) return null\n        const m = String(soldCommentText).match(/\\bto\\s+([A-Za-z0-9_]{2,})\\b/i)\n        return m?.[1] ? String(m[1]).trim() : null\n      })()\n\n      const inferredFinalPrice =\n        (typeof extListing?.final_price === 'number' && Number.isFinite(extListing.final_price) && extListing.final_price > 0)\n          ? Math.floor(extListing.final_price)\n          : (inferredSoldPriceFromComment || null)\n\n      const inferredSaleDate = (() => {\n        const t = extListing?.sold_at || extListing?.end_date || null\n        if (!t) return null\n        const d = new Date(t)\n        if (!Number.isFinite(d.getTime())) return null\n        return d.toISOString().split('T')[0]\n      })()\n\n      const inferredStatus = (() => {\n        const s = String(extListing?.listing_status || '').toLowerCase()\n        if (s === 'sold') return 'sold'\n        if (s === 'active' || s === 'live') return 'active'\n        if (s === 'ended' || s === 'complete' || s === 'completed') return 'ended'\n        // If we inferred a sold price from comments, treat as sold.\n        if (inferredFinalPrice && inferredFinalPrice > 0) return 'sold'\n        return null\n      })()\n\n      // If we inferred SOLD (either from the system comment or from an existing external_listings.final_price),\n      // persist it back into external_listings so the rest of the system (auctionPulse, header owner guess, etc.)\n      // becomes consistent. Also ensure `current_bid` matches `final_price` for sold listings.\n      if (extListing?.id && inferredFinalPrice && inferredFinalPrice > 0) {\n        const existingStatus = String(extListing?.listing_status || '').toLowerCase()\n        const existingFinal =\n          (typeof extListing?.final_price === 'number' && Number.isFinite(extListing.final_price) && extListing.final_price > 0)\n            ? Math.floor(extListing.final_price)\n            : null\n        const existingCurrent =\n          (typeof extListing?.current_bid === 'number' && Number.isFinite(extListing.current_bid) && extListing.current_bid > 0)\n            ? Math.floor(extListing.current_bid)\n            : null\n\n        const needsSync =\n          existingStatus !== 'sold' ||\n          existingFinal !== inferredFinalPrice ||\n          existingCurrent !== inferredFinalPrice\n\n        if (needsSync) {\n          const existingMeta = (extListing as any)?.metadata && typeof (extListing as any).metadata === 'object'\n            ? (extListing as any).metadata\n            : {}\n          const reserveFromHtml =\n            html.includes('no-reserve') || /\\bNo Reserve\\b/i.test(html) ? 'no_reserve' : null\n\n          await supabase\n            .from('external_listings')\n            .update({\n              listing_status: 'sold',\n              final_price: inferredFinalPrice,\n              current_bid: inferredFinalPrice,\n              sold_at: extListing?.sold_at || extListing?.end_date || nowIso,\n              metadata: {\n                ...existingMeta,\n                ...(inferredBuyerFromComment ? { buyer_username: inferredBuyerFromComment } : {}),\n                ...(reserveFromHtml ? { reserve_status: reserveFromHtml } : {}),\n                source: existingMeta?.source || 'extract-auction-comments',\n              },\n              updated_at: nowIso,\n            })\n            .eq('id', extListing.id)\n        }\n      }\n\n      const listingPayload: any = {\n        vehicle_id: vehicleId,\n        bat_listing_url: String(auctionUrlNorm),\n        bat_lot_number: extListing?.listing_id ? String(extListing.listing_id) : null,\n        listing_status: inferredStatus || undefined,\n        comment_count: commentsWithIdentities.length,\n        bid_count: commentsWithIdentities.filter((c: any) => typeof c?.bid_amount === 'number' && Number.isFinite(c.bid_amount) && c.bid_amount > 0).length,\n        sale_price: inferredFinalPrice,\n        final_bid: inferredFinalPrice || (inferredHighBid > 0 ? Math.floor(inferredHighBid) : null),\n        sale_date: inferredFinalPrice ? inferredSaleDate : null,\n        auction_end_date: inferredSaleDate || undefined,\n        last_updated_at: nowIso,\n        updated_at: nowIso,\n        raw_data: {\n          source: 'extract-auction-comments',\n          auction_event_id: eventId,\n          last_extracted_at: nowIso,\n        }\n      }\n\n      const { data: upsertedListing, error: upsertListingErr } = await supabase\n        .from('bat_listings')\n        .upsert(listingPayload, { onConflict: 'bat_listing_url' })\n        .select('id')\n        .single()\n      if (!upsertListingErr && upsertedListing?.id) {\n        batListingId = String(upsertedListing.id)\n      }\n\n      if (batListingId) {\n        const batCommentRows = commentsWithIdentities.map((c: any) => ({\n          bat_listing_id: batListingId,\n          vehicle_id: vehicleId,\n          bat_username: String(c.author_username || 'Unknown'),\n          external_identity_id: c.external_identity_id,\n          content_hash: c.content_hash,\n          comment_text: String(c.comment_text || ''),\n          comment_html: null,\n          comment_timestamp: c.posted_at,\n          scraped_at: nowIso,\n          bat_comment_id: null,\n          comment_url: null,\n          is_seller_comment: !!c.is_seller,\n          likes_count: typeof c.comment_likes === 'number' && Number.isFinite(c.comment_likes) ? Math.max(0, Math.floor(c.comment_likes)) : 0,\n          replies_count: 0,\n          parent_comment_id: null,\n          updated_at: nowIso,\n        }))\n\n        await supabase\n          .from('bat_comments')\n          .upsert(batCommentRows, { onConflict: 'bat_listing_id,content_hash' })\n\n        const bidRows = commentsWithIdentities\n          .filter((c: any) => typeof c?.bid_amount === 'number' && Number.isFinite(c.bid_amount) && c.bid_amount > 0)\n          .map((c: any) => ({\n            bat_listing_id: batListingId,\n            vehicle_id: vehicleId,\n            bat_user_id: null,\n            bat_username: String(c.author_username || 'Unknown'),\n            external_identity_id: c.external_identity_id,\n            bid_amount: c.bid_amount,\n            bid_timestamp: c.posted_at,\n            is_winning_bid: false,\n            is_final_bid: false,\n            source: 'comment',\n            bat_comment_id: null,\n            auction_event_id: eventId,\n            metadata: {\n              source_url: String(auctionUrlNorm),\n              comment_content_hash: c.content_hash,\n              sequence_number: c.sequence_number,\n            },\n            updated_at: nowIso,\n          }))\n\n        if (bidRows.length > 0) {\n          await supabase\n            .from('bat_bids')\n            .upsert(bidRows, { onConflict: 'bat_listing_id,bat_username,bid_amount,bid_timestamp' })\n        }\n\n        if (inferredStatus || inferredFinalPrice || inferredHighBid > 0) {\n          const maxBid = bidRows\n            .map((b: any) => (typeof b?.bid_amount === 'number' && Number.isFinite(b.bid_amount) ? b.bid_amount : null))\n            .filter((n: any) => typeof n === 'number')\n            .reduce((acc: number, n: number) => (n > acc ? n : acc), 0)\n\n          await supabase\n            .from('bat_listings')\n            .update({\n              comment_count: batCommentRows.length,\n              bid_count: bidRows.length,\n              final_bid: inferredFinalPrice || (maxBid > 0 ? Math.floor(maxBid) : null),\n              sale_price: inferredFinalPrice,\n              sale_date: inferredFinalPrice ? inferredSaleDate : null,\n              listing_status: inferredStatus || undefined,\n              last_updated_at: nowIso,\n              updated_at: nowIso,\n            })\n            .eq('id', batListingId)\n        }\n      }\n    } catch (e: any) {\n      console.warn('BaT table upserts failed (non-fatal):', e?.message || String(e))\n    }\n\n    // Trigger AI analysis on comments (async, don't wait)\n    if (comments.length > 0) {\n      const anonJwt = Deno.env.get('SUPABASE_ANON_KEY') ?? Deno.env.get('ANON_KEY') ?? ''\n      const inboundAuth = req.headers.get('Authorization') || ''\n      const authToUse = inboundAuth || (anonJwt.startsWith('eyJ') ? `Bearer ${anonJwt}` : '')\n      fetch(`${Deno.env.get('SUPABASE_URL')}/functions/v1/analyze-auction-comments`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          // analyze-auction-comments is deployed with verify_jwt enabled.\n          ...(authToUse ? { 'Authorization': authToUse } : {})\n        },\n        body: JSON.stringify({ auction_event_id: eventId })\n      }).catch(e => console.error('Failed to trigger analysis:', e))\n    }\n\n    return new Response(JSON.stringify({\n      success: true,\n      comments_extracted: comments.length,\n      auction_event_id: eventId,\n      vehicle_id: vehicleId\n    }), {\n      headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n    })\n\n  } catch (error) {\n    const e: any = error\n    const message =\n      e instanceof Error\n        ? e.message\n        : typeof e?.message === 'string'\n          ? e.message\n          : (() => {\n              try {\n                return JSON.stringify(e)\n              } catch {\n                return String(e)\n              }\n            })()\n\n    const details =\n      typeof e?.details === 'string'\n        ? e.details\n        : (() => {\n            try {\n              return e?.details ? JSON.stringify(e.details) : null\n            } catch {\n              return null\n            }\n          })()\n\n    const hint =\n      typeof e?.hint === 'string'\n        ? e.hint\n        : (() => {\n            try {\n              return e?.hint ? JSON.stringify(e.hint) : null\n            } catch {\n              return null\n            }\n          })()\n\n    const code = typeof e?.code === 'string' ? e.code : null\n\n    console.error('Error:', { message, code, details, hint, raw: e })\n\n    return new Response(JSON.stringify({ error: message, code, details, hint }), {\n      status: 500,\n      headers: { ...corsHeaders, 'Content-Type': 'application/json' }\n    })\n  }\n})\n\nfunction parseBaTDate(dateStr: string, referenceDate: Date): Date {\n  // Try \"12/27/24 at 6:01 PM\" format first\n  const dateTimeMatch = dateStr.match(/(\\d{1,2})\\/(\\d{1,2})\\/(\\d{2,4})\\s+at\\s+(\\d+):(\\d+)\\s+(AM|PM)/i)\n  if (dateTimeMatch) {\n    const [, month, day, year, hour, minute, ampm] = dateTimeMatch\n    const fullYear = year.length === 2 ? 2000 + parseInt(year) : parseInt(year)\n    const date = new Date(fullYear, parseInt(month) - 1, parseInt(day), \n      parseInt(hour) + (ampm.toUpperCase() === 'PM' && hour !== '12' ? 12 : 0) + (ampm.toUpperCase() === 'AM' && hour === '12' ? -12 : 0), \n      parseInt(minute))\n    if (!isNaN(date.getTime())) return date\n  }\n  \n  // Try \"Nov 21 at 3:38 PM\" format\n  const match = dateStr.match(/([A-Za-z]+)\\s+(\\d+)\\s+at\\s+(\\d+):(\\d+)\\s+(AM|PM)/)\n  if (!match) return new Date()\n  \n  const [, month, day, hour, minute, ampm] = match\n  const year = referenceDate.getFullYear()\n  \n  const date = new Date(`${month} ${day}, ${year}`)\n  let hours = parseInt(hour)\n  if (ampm === 'PM' && hours !== 12) hours += 12\n  if (ampm === 'AM' && hours === 12) hours = 0\n  \n  date.setHours(hours, parseInt(minute))\n  return date\n}\n\nfunction extractNumber(text: string | null | undefined): number {\n  if (!text) return 0\n  const match = text.match(/(\\d+)/)\n  return match ? parseInt(match[1]) : 0\n}\n\n"