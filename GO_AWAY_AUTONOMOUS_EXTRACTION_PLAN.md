# üöÄ Autonomous Extraction Plan - Go Away for Hours

## ‚úÖ CURRENT SYSTEM STATUS

### **Supabase Project**
- **Project**: `nuke` (qkgaybvrernstplzjaam)
- **Region**: West US (North California)
- **Status**: ‚úÖ LINKED & ACTIVE

### **Database Capacity**
- **Total Size**: ~2.1 GB
- **Vehicles**: 9,542
- **Images**: 382,826 (1.4 GB - largest table)
- **External Listings**: 1,236 (2 live auctions)
- **Organizations**: 296
- **Identities**: 9,969

### **Import Queue Health**
- ‚úÖ **Complete**: 7,708 items
- ‚ö†Ô∏è **Failed**: 4,112 items (need review)
- üîÑ **Processing**: 751 items (active)
- ‚è≥ **Pending**: 70 items (ready to process)
- üìã **Duplicate**: 981 items (filtered)

### **Edge Functions Deployed**
- ‚úÖ **181 functions** deployed to cloud
- ‚úÖ **sync-active-auctions** (v6) - Updated 12/29 12:49
- ‚úÖ **extract-premium-auction** (v105) - Updated 12/29 12:58
- ‚úÖ **process-import-queue** (v85) - Active
- ‚úÖ **sync-bat-listing** (v49) - Active
- ‚úÖ **extract-bat-profile-vehicles** (v15) - Active

---

## ü§ñ WHAT'S RUNNING AUTONOMOUSLY (While You're Gone)

### **Every 1 Minute:**
```
‚úÖ process-import-queue-manual
   ‚îî‚îÄ> Processes 10 items from import_queue
   ‚îî‚îÄ> Creates vehicle records, downloads images
   ‚îî‚îÄ> ~600 vehicles/hour sustained
```

### **Every 3 Minutes (Overnight: 8PM-7AM):**
```
‚úÖ overnight-extraction-pulse  
   ‚îú‚îÄ> process-import-queue (100 items/batch)
   ‚îú‚îÄ> process-bat-extraction-queue (50 BaT listings)
   ‚îú‚îÄ> go-grinder (chain_depth=10, max=1000 listings)
   ‚îî‚îÄ> autonomous-extraction-agent (smart discovery)
```

### **Every 5 Minutes:**
```
‚úÖ craigslist-squarebodies-5m (20 regions, 60 listings each)
‚úÖ process-service-queue (background tasks)
‚úÖ micro-scrape-bandaid (quick fixes)
```

### **Every 15 Minutes:**
```
‚úÖ sync-active-auctions ‚Üí Updates ALL live auction bids/timers
‚úÖ cars-and-bids-15m ‚Üí Scrapes C&B active auctions (max 20)
‚úÖ mecum-15m ‚Üí Scrapes Mecum live auctions (max 20)
‚úÖ barrett-jackson-15m ‚Üí Scrapes B-J live auctions (max 20)
```

### **Hourly:**
```
‚úÖ analyze-unprocessed-org-images
‚úÖ source-health-monitor
‚úÖ hourly-scraper-health-check
```

### **Daily (2AM PST):**
```
‚úÖ daily-craigslist-squarebodies (comprehensive sweep)
‚úÖ daily-production-run (full system check)
‚úÖ enrich-organizations-daily (50 orgs)
```

---

## üìä HOW TO MONITOR PROGRESS

### **Option 1: Supabase Dashboard** (Easiest)
1. Go to: https://supabase.com/dashboard/project/qkgaybvrernstplzjaam
2. Click **SQL Editor** ‚Üí **New query**
3. Paste contents of: `scripts/monitor-autonomous-extraction.sql`
4. Click **Run** - shows full dashboard

### **Option 2: Quick Stats via Terminal**
```bash
cd /Users/skylar/nuke

# Check queue status
npx supabase db remote exec "
SELECT status, COUNT(*) 
FROM import_queue 
GROUP BY status 
ORDER BY COUNT(*) DESC;
"

# Check live auctions
npx supabase db remote exec "
SELECT platform, COUNT(*), MAX(current_bid) as highest_bid
FROM external_listings 
WHERE end_date > NOW() 
GROUP BY platform;
"

# Check recent activity (last hour)
npx supabase db remote exec "
SELECT COUNT(*) as new_vehicles
FROM vehicles 
WHERE created_at > NOW() - INTERVAL '1 hour';
"
```

### **Option 3: Real-Time Logs** (Advanced)
```bash
# Watch Edge Function logs
npx supabase functions logs sync-active-auctions --tail

# Watch database logs
npx supabase db logs --tail
```

---

## üéØ EXPECTED PROGRESS (While You're Away)

### **Conservative Estimate (4 hours):**
```
Vehicles extracted:       ~2,400  (600/hour from queue processing)
Images downloaded:        ~48,000 (20 images/vehicle avg)
External listings synced: ~16     (every 15 min for 4 hours)
Queue items processed:    ~2,400  (10/min baseline + batches)
Cron jobs executed:       ~200+   (various schedules)
```

### **Aggressive Estimate (4 hours, if queue is hot):**
```
Vehicles extracted:       ~6,000  (go-grinder + overnight pulse)
Images downloaded:        ~120,000
External listings synced: ~16
Organizations created:    ~50-100 (from discovered sellers)
Identities created:       ~500+   (sellers, bidders discovered)
```

---

## üö¶ WHAT TO CHECK WHEN YOU RETURN

### **1. Check System Health**
```bash
cd /Users/skylar/nuke
npx supabase db remote exec "$(cat scripts/monitor-autonomous-extraction.sql)"
```

Look for:
- ‚úÖ **Green "HEALTHY"** status
- ‚ö†Ô∏è **Yellow warnings** ‚Üí investigate but not critical
- üî¥ **Red critical** ‚Üí pause crons, investigate failures

### **2. Check Queue Backlog**
```sql
SELECT status, COUNT(*) FROM import_queue GROUP BY status;
```

Expected after 4 hours:
- **Pending**: Should be LOW (<100) if system is keeping up
- **Processing**: Some items in flight (normal)
- **Complete**: Should INCREASE by ~2,400+
- **Failed**: Review if > 5,000

### **3. Check Live Auctions**
```sql
SELECT * FROM external_listings WHERE end_date > NOW();
```

Should show:
- ‚úÖ Current bids updating (not stale)
- ‚úÖ Timers counting down
- ‚úÖ New auctions discovered

### **4. Visual Check**
1. Open: http://localhost:5174/auctions
2. Should show updated bid amounts
3. Timers should be counting down in real-time

---

## üõë HOW TO PAUSE EXTRACTION (If Needed)

### **Pause All Autonomous Activity:**
```sql
-- In Supabase SQL Editor:
UPDATE cron.job SET active = false 
WHERE jobname LIKE '%extraction%' 
   OR jobname LIKE '%grinder%'
   OR jobname LIKE '%import-queue%';
```

### **Resume When Ready:**
```sql
UPDATE cron.job SET active = true 
WHERE jobname LIKE '%extraction%' 
   OR jobname LIKE '%grinder%'
   OR jobname LIKE '%import-queue%';
```

---

## üéØ SPECIFIC EXTRACTION SOURCES

### **Bring a Trailer (https://bringatrailer.com/auctions/)**
- **Handled by**: `sync-active-auctions` (every 15 min)
- **Current live**: 2 auctions (updated 12/29 14:00)
- **Method**: Updates `external_listings` with current_bid, bid_count, watcher_count
- **Storage**: `external_listings` (platform='bat')

### **Cars & Bids (https://carsandbids.com/)**
- **Handled by**: `cars-and-bids-15m` cron (every 15 min)
- **Method**: Calls `extract-premium-auction` with site_type='carsandbids'
- **Max per run**: 20 vehicles
- **Storage**: `vehicles` + `external_listings` (platform='carsandbids')

### **PCarMarket (https://pcarmarket.com/)**
- **Not automated yet** - needs manual trigger or cron setup
- **To add**: Create cron job calling `scrape-multi-source` or `extract-premium-auction`

---

## üî• MANUAL TRIGGERS (If You Want to Speed Things Up Before Leaving)

### **Kick Off BaT Batch Extraction (462 live auctions)**
```bash
curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/sync-active-auctions" \
  -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 500, "force_update": true}'
```

### **Extract Cars & Bids Active Auctions**
```bash
curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/extract-premium-auction" \
  -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://carsandbids.com/auctions", "site_type": "carsandbids", "max_vehicles": 100}'
```

### **Extract PCarMarket Listings**
```bash
curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/scrape-multi-source" \
  -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
  -H "Content-Type: application/json" \
  -d '{"url": "https://pcarmarket.com/auctions", "max_pages": 10}'
```

### **Force Process Queue (Clear Backlog)**
```bash
curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/process-import-queue" \
  -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 100, "max_batches": 50}'
```

---

## üìà CAPACITY PROJECTIONS

### **Current Usage:**
- **Database**: 2.1 GB / 8 GB (Pro plan) = **26% used**
- **Storage**: 1.4 GB (images) / 100 GB = **1.4% used**
- **Edge Functions**: ~180 active / unlimited

### **After 4 Hours (Conservative):**
- **Database**: ~2.3 GB (+200 MB for 2,400 vehicles)
- **Storage**: ~1.9 GB (+500 MB for 48,000 images)
- **Still well within limits** ‚úÖ

### **After 24 Hours (If Queue Snowballs):**
- **Database**: ~3.5 GB (+1.4 GB for 14,400 vehicles)
- **Storage**: ~4.4 GB (+3 GB for 288,000 images)
- **Still safe** ‚úÖ (43% database, 4% storage)

---

## üéØ THE PLAN

### **Before You Leave (Do This Now):**

1. **Deploy latest frontend fixes** (already done via Vercel)
   
2. **Verify crons are running:**
   ```sql
   SELECT jobname, active FROM cron.job WHERE active = true;
   ```

3. **Optional: Kick off initial extraction** (speeds things up):
   ```bash
   # BaT (queues 462 live auctions)
   curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/sync-active-auctions" \
     -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
     -H "Content-Type: application/json" \
     -d '{"batch_size": 500}'
   
   # Cars & Bids
   curl -X POST "https://qkgaybvrernstplzjaam.supabase.co/functions/v1/extract-premium-auction" \
     -H "Authorization: Bearer $(grep SUPABASE_SERVICE_ROLE_KEY nuke_frontend/.env.local | cut -d '=' -f2)" \
     -H "Content-Type: application/json" \
     -d '{"url": "https://carsandbids.com/auctions", "site_type": "carsandbids", "max_vehicles": 100}'
   ```

### **While You're Away:**
- ‚úÖ Crons run automatically (no action needed)
- ‚úÖ Queue processes continuously (10-100 items/min)
- ‚úÖ Live auctions sync every 15 min
- ‚úÖ New vehicles discovered and queued
- ‚úÖ Images downloaded automatically

### **When You Return:**

1. **Run monitoring dashboard:**
   ```bash
   cd /Users/skylar/nuke
   npx supabase db remote exec "$(cat scripts/monitor-autonomous-extraction.sql)"
   ```

2. **Check system health** (should see):
   - üü¢ HEALTHY status
   - ‚úÖ Pending queue <100 items
   - ‚úÖ 2,000-6,000 new vehicles added
   - ‚úÖ Live auctions updating

3. **Review any failures:**
   ```sql
   SELECT listing_url, error_message, attempts
   FROM import_queue
   WHERE status = 'failed' AND last_attempt_at > NOW() - INTERVAL '6 hours'
   ORDER BY last_attempt_at DESC
   LIMIT 20;
   ```

4. **Visual verification:**
   - Open: http://localhost:5174/auctions
   - Should show updated bids/timers
   - New vehicles on homepage

---

## üîß TROUBLESHOOTING

### **If Queue Gets Stuck (Pending > 10,000):**
```sql
-- Pause discovery crons:
UPDATE cron.job SET active = false WHERE jobname LIKE '%grinder%' OR jobname LIKE '%discovery%';

-- Focus on processing:
UPDATE cron.job SET active = true WHERE jobname LIKE '%process-import-queue%';
```

### **If Failures Spike (Failed > 10,000):**
```sql
-- Review common errors:
SELECT error_message, COUNT(*) as count
FROM import_queue
WHERE status = 'failed'
GROUP BY error_message
ORDER BY count DESC
LIMIT 10;

-- Reset failed items for retry (if fixable):
UPDATE import_queue
SET status = 'pending', attempts = 0
WHERE status = 'failed' AND attempts < 3;
```

### **If Database Fills Up (>7GB):**
```sql
-- Delete old debug logs:
DELETE FROM debug_runtime_logs WHERE created_at < NOW() - INTERVAL '7 days';

-- Archive old scraping health:
DELETE FROM scraping_health WHERE created_at < NOW() - INTERVAL '30 days';
```

---

## üéØ SNOWBALL EFFECT CONTROL

### **Current Safeguards (Already Active):**

1. ‚úÖ **Deduplication**: `import_queue.listing_url` UNIQUE prevents double-queuing
2. ‚úÖ **Atomic Locking**: `claim_import_queue_batch()` prevents concurrent processing
3. ‚úÖ **Priority Queue**: High-value items processed first
4. ‚úÖ **Rate Limiting**: Delays between API calls
5. ‚úÖ **Batch Limits**: Max 100 items/batch prevents runaway

### **What Triggers Snowballing:**
```
Extract BaT listing
  ‚îî‚îÄ> Discovers seller "wrenchmonkey72"
      ‚îî‚îÄ> extract-bat-profile-vehicles (queues 50 vehicles)
          ‚îî‚îÄ> Each vehicle discovers NEW sellers
              ‚îî‚îÄ> Each NEW seller triggers profile extraction
                  ‚îî‚îÄ> Exponential growth!
```

### **How It's Controlled:**
```
1. All discoveries ‚Üí import_queue (queued, not immediate)
2. Queue processes in batches (10-100 at a time)
3. If queue > 10,000: daytime crons automatically slow down
4. Seller profile extraction has LOW priority (processed last)
5. Monitoring alerts if queue exceeds thresholds
```

---

## ‚úÖ YOU'RE GOOD TO GO!

### **Summary:**
- ‚úÖ 181 Edge Functions deployed to cloud
- ‚úÖ 15+ cron jobs running autonomously
- ‚úÖ Import queue processing 600-6,000 vehicles/hour
- ‚úÖ Live auctions syncing every 15 minutes
- ‚úÖ Database has plenty of capacity (26% used)
- ‚úÖ Monitoring dashboard ready to use

### **Expected Results After 4 Hours:**
- **Vehicles**: 9,542 ‚Üí **12,000-15,000** (+2,500-5,500)
- **Images**: 382,826 ‚Üí **430,000-500,000** (+50,000-120,000)
- **Live Auctions**: 2 ‚Üí **2-10** (if new ones start)
- **Queue**: Pending should decrease or stay manageable

### **The System Will:**
- ‚úÖ Keep live auction bids/timers updated
- ‚úÖ Process queued vehicle extractions
- ‚úÖ Download images automatically
- ‚úÖ Create organizations from discovered sellers
- ‚úÖ Handle the snowball effect gracefully

**You can leave now - the cloud will keep grinding!** üöÄ

